{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfOuFKWWbhwz",
        "outputId": "1b88bb72-8677-4d82-92e2-9b203b45a385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "# # Load compressed models from tensorflow_hub\n",
        "# os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12, 12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "import streamlit as st\n",
        "import os.path\n",
        "import time\n",
        "\n",
        "\n",
        "def trainFunc(content_path,style_path):\n",
        "\n",
        "\n",
        "    def tensor_to_image(tensor):\n",
        "        tensor = tensor*255\n",
        "        tensor = np.array(tensor, dtype=np.uint8)\n",
        "        if np.ndim(tensor)>3:\n",
        "            assert tensor.shape[0] == 1\n",
        "            tensor = tensor[0]\n",
        "        return PIL.Image.fromarray(tensor)\n",
        "\n",
        "    content_path = content_path\n",
        "    style_path = style_path\n",
        "\n",
        "    def load_img(path_to_img):\n",
        "        max_dim = 512\n",
        "        img = tf.io.read_file(path_to_img)\n",
        "        img = tf.image.decode_image(img, channels=3)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "        shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "        long_dim = max(shape)\n",
        "        scale = max_dim / long_dim\n",
        "\n",
        "        new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "        img = tf.image.resize(img, new_shape)\n",
        "        img = img[tf.newaxis, :]\n",
        "        return img\n",
        "\n",
        "    def imshow(image, title=None):\n",
        "        if len(image.shape) > 3:\n",
        "            image = tf.squeeze(image, axis=0)\n",
        "\n",
        "        plt.imshow(image)\n",
        "        if title:\n",
        "            plt.title(title)\n",
        "\n",
        "\n",
        "    content_image = load_img(content_path)\n",
        "    style_image = load_img(style_path)\n",
        "\n",
        "\n",
        "\n",
        "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "\n",
        "\n",
        "    content_layers = ['block5_conv2']\n",
        "\n",
        "    style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1',\n",
        "                'block4_conv1',\n",
        "                'block5_conv1']\n",
        "\n",
        "    num_content_layers = len(content_layers)\n",
        "    num_style_layers = len(style_layers)\n",
        "\n",
        "    def vgg_layers(layer_names):\n",
        "        \"\"\" Creates a VGG model that returns a list of intermediate output values.\"\"\"\n",
        "        # Load our model. Load pretrained VGG, trained on ImageNet data\n",
        "        vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "        vgg.trainable = False\n",
        "\n",
        "        outputs = [vgg.get_layer(name).output for name in layer_names]\n",
        "\n",
        "        model = tf.keras.Model([vgg.input], outputs)\n",
        "        return model\n",
        "\n",
        "\n",
        "    def gram_matrix(input_tensor):\n",
        "        result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "        return result/(num_locations)\n",
        "\n",
        "\n",
        "    class StyleContentModel(tf.keras.models.Model):\n",
        "        def __init__(self, style_layers, content_layers):\n",
        "            super(StyleContentModel, self).__init__()\n",
        "            self.vgg = vgg_layers(style_layers + content_layers)\n",
        "            self.style_layers = style_layers\n",
        "            self.content_layers = content_layers\n",
        "            self.num_style_layers = len(style_layers)\n",
        "            self.vgg.trainable = False\n",
        "\n",
        "        def call(self, inputs):\n",
        "            \"Expects float input in [0,1]\"\n",
        "            inputs = inputs*255.0\n",
        "            preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "            outputs = self.vgg(preprocessed_input)\n",
        "            style_outputs, content_outputs = (outputs[:self.num_style_layers],\n",
        "                                            outputs[self.num_style_layers:])\n",
        "\n",
        "            style_outputs = [gram_matrix(style_output)\n",
        "                            for style_output in style_outputs]\n",
        "\n",
        "            content_dict = {content_name: value\n",
        "                            for content_name, value\n",
        "                            in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "            style_dict = {style_name: value\n",
        "                        for style_name, value\n",
        "                        in zip(self.style_layers, style_outputs)}\n",
        "\n",
        "            return {'content': content_dict, 'style': style_dict}\n",
        "\n",
        "    extractor = StyleContentModel(style_layers, content_layers)\n",
        "    style_targets = extractor(style_image)['style']\n",
        "    content_targets = extractor(content_image)['content']\n",
        "    image = tf.Variable(content_image)\n",
        "\n",
        "    def clip_0_1(image):\n",
        "      return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "    style_weight=1e-2\n",
        "    content_weight=1e4\n",
        "\n",
        "    def style_content_loss(outputs):\n",
        "        style_outputs = outputs['style']\n",
        "        content_outputs = outputs['content']\n",
        "        style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2)\n",
        "                            for name in style_outputs.keys()])\n",
        "        style_loss *= style_weight / num_style_layers\n",
        "\n",
        "        content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2)\n",
        "                                for name in content_outputs.keys()])\n",
        "        content_loss *= content_weight / num_content_layers\n",
        "        loss = style_loss + content_loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "    @tf.function()\n",
        "    def train_step(image):\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = extractor(image)\n",
        "            loss = style_content_loss(outputs)\n",
        "\n",
        "        grad = tape.gradient(loss, image)\n",
        "        opt.apply_gradients([(grad, image)])\n",
        "        image.assign(clip_0_1(image))\n",
        "\n",
        "        no_of_train=0\n",
        "\n",
        "\n",
        "    import time\n",
        "    start = time.time()\n",
        "    imageFinal=image\n",
        "    epochs = 1\n",
        "    steps_per_epoch = 100\n",
        "    step = 0\n",
        "    for n in range(epochs):\n",
        "        for m in range(steps_per_epoch):\n",
        "            step += 1\n",
        "            train_step(image)\n",
        "#   display.clear_output(wait=True)\n",
        "  # image.save(f\"/content/Finalimage.jpg\")\n",
        "    save_img('/content/Finalimage.jpg', tensor_to_image(image))\n",
        "    end = time.time()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_uploadedfile(uploadedfile,name):\n",
        "     with open(os.path.join(\".\",name),\"wb\") as f:\n",
        "         f.write(uploadedfile.getbuffer())\n",
        "     return st.success(\"File Uploaded\")\n",
        "\n",
        "st.write(\"# Neural Style Transfer\")\n",
        "st.write(\"## Upload The Image and the Style\")\n",
        "\n",
        "uploaded_image = st.file_uploader(\"Upload the Image\")\n",
        "uploaded_design = st.file_uploader(\"Upload the Style\")\n",
        "if uploaded_image is not None and uploaded_design is not None:\n",
        "    # print(uploaded_file)\n",
        "    image = PIL.Image.open(uploaded_image)\n",
        "    design = PIL.Image.open(uploaded_design)\n",
        "    st.image(image, caption='Image')\n",
        "    st.image(design, caption='Design')\n",
        "    save_uploadedfile(uploaded_image,\"image.jpg\")\n",
        "    save_uploadedfile(uploaded_design,\"design.jpg\")\n",
        "    st.button('Train Image', on_click=trainFunc,args=(\"/content/image.jpg\",\"/content/design.jpg\"))\n",
        "\n",
        "\n",
        "while True:\n",
        "        if os.path.isfile(\"/content/Finalimage.jpg\") :\n",
        "            st.success(\"Result: \")\n",
        "            FinalImage=PIL.Image.open(\"/content/Finalimage.jpg\")\n",
        "            st.image(FinalImage, caption='Image')\n",
        "            break\n",
        "        time.sleep(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsuUdEQmbj8q",
        "outputId": "da1c6261-6e57-46c5-aa95-e0d06e869c34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrNwultvbp8f",
        "outputId": "abb48b5e-4faa-4fd1-9fb0-db7d21a97a2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[..................] | fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.6.135:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.678s\n",
            "your url is: https://empty-hornets-sin.loca.lt\n",
            "2023-11-13 08:11:08.489633: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-13 08:11:08.489696: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-13 08:11:08.489742: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-13 08:11:08.503114: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-13 08:11:10.018897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-13 08:12:43.752000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:43.793108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:43.793435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:43.794507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:43.794811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:43.795021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:44.805474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:44.805873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:44.806075: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-13 08:12:44.806225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-13 08:12:44.806417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-13 08:12:46.628923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8900\n",
            "2023-11-13 08:12:52.825853: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7d025df5b610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-11-13 08:12:52.825900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-11-13 08:12:52.831399: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-11-13 08:12:52.960270: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wV9Vn1xFb1sH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}